import requests
import json
from typing import List, Dict
import time
import os
import argparse

def parse_args():
    parser = argparse.ArgumentParser(
        description="ç½‘ç»œçƒ­æœåˆ†æå·¥å…· - å¯é…ç½®åŒ–ç‰ˆæœ¬ (Powered by Ollama)"
    )

    parser.add_argument("--hot-search-api", type=str, required=True,
                        help="çƒ­æœæ•°æ®æ¥å£åœ°å€ï¼Œä¾‹å¦‚ http://192.168.0.1:10880")

    parser.add_argument("--ollama-api", type=str, required=True,
                        help="Ollama API åœ°å€ï¼Œä¾‹å¦‚ http://192.168.0.1:11434")

    parser.add_argument("--ollama-model", type=str, default="qwen2.5:14b",
                        help="Ollama æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen2.5:14bï¼‰")

    parser.add_argument("--save-dir", type=str, default=os.path.expanduser("~/hot_trends_analysis/outputs"),
                        help="ç»“æœä¿å­˜ç›®å½•")

    parser.add_argument("--platforms", type=str, nargs="+", default=[
        "weibo", "zhihu", "baidu", "bilibili", "douyin",
        "toutiao", "36kr", "ithome", "github", "hackernews"
    ], help="è¦åˆ†æçš„å¹³å°åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰")

    parser.add_argument("--topics-per-platform", type=int, default=10,
                        help="æ¯ä¸ªå¹³å°æå–çš„çƒ­æœæ¡æ•°")

    parser.add_argument("--max-retries", type=int, default=5,
                        help="æœ€å¤§é‡è¯•æ¬¡æ•°")

    parser.add_argument("--retry-delay", type=float, default=1,
                        help="é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰")

    return parser.parse_args()


def fetch_hot_search(platform: str, api_url: str, max_retries: int, retry_delay: float) -> Dict:
    """è·å–æŒ‡å®šå¹³å°çš„çƒ­æœæ•°æ®ï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•"""
    for attempt in range(1, max_retries + 1):
        try:
            url = f"{api_url}/{platform}"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸  è·å– {platform} æ•°æ®å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                print(f"   ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"âŒ è·å– {platform} æ•°æ®å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                return None
    return None


def extract_hot_topics(data: Dict, platform: str, topics_per_platform: int) -> List[str]:
    """ä»APIè¿”å›çš„æ•°æ®ä¸­æå–çƒ­æœæ ‡é¢˜"""
    topics = []
    try:
        if data and "data" in data:
            items = data["data"]
            for item in items[:topics_per_platform]:
                title = item.get("title", "")
                if title:
                    topics.append(title)
    except Exception as e:
        print(f"âš ï¸  è§£æ {platform} æ•°æ®æ—¶å‡ºé”™: {e}")
    return topics


def call_ollama(prompt: str, ollama_api: str, model_name: str,
                max_retries: int, retry_delay: float) -> str:
    """è°ƒç”¨æœ¬åœ°Ollamaè¿›è¡Œåˆ†æï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•"""
    for attempt in range(1, max_retries + 1):
        try:
            payload = {
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 800,
                    "num_ctx": 2048
                }
            }

            chat_api = f"{ollama_api}/api/chat"
            if attempt == 1:
                print(f"ğŸ”— è°ƒç”¨ Ollama API: {chat_api}")

            response = requests.post(chat_api, json=payload, timeout=180)
            response.raise_for_status()
            result = response.json()

            if "message" in result and "content" in result["message"]:
                return result["message"]["content"]
            return ""
        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸  Ollama è°ƒç”¨å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                print(f"   ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"âŒ Ollama è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                return ""
    return ""


def ensure_ollama_model(ollama_api: str, model_name: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ‹‰å–"""
    try:
        response = requests.get(f"{ollama_api}/api/tags", timeout=10)
        response.raise_for_status()
        models = response.json().get("models", [])
        model_names = [m["name"] for m in models]

        if model_name in model_names:
            print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_name}")
            return True

        print(f"ğŸ“¦ æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ‹‰å–: {model_name} ...")
        pull_response = requests.post(f"{ollama_api}/api/pull", json={"name": model_name}, stream=True, timeout=600)

        for line in pull_response.iter_lines():
            if line:
                try:
                    msg = json.loads(line.decode('utf-8'))
                    status = msg.get("status")
                    if status:
                        print(f"   {status}")
                except json.JSONDecodeError:
                    pass

        print(f"âœ… æ¨¡å‹æ‹‰å–å®Œæˆ: {model_name}")
        return True
    except Exception as e:
        print(f"âŒ æ£€æŸ¥/æ‹‰å–æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return False


def analyze_hot_trends(args):
    """ä¸»å‡½æ•°ï¼šåˆ†æç½‘ç»œçƒ­é—¨è¶‹åŠ¿"""
    print("ğŸš€ å¼€å§‹æ”¶é›†çƒ­æœæ•°æ®...\n")

    if not ensure_ollama_model(args.ollama_api, args.ollama_model):
        print("âŒ æ— æ³•å‡†å¤‡ Ollama æ¨¡å‹ï¼Œç»ˆæ­¢åˆ†æã€‚")
        return

    all_topics = {}

    for platform in args.platforms:
        print(f"ğŸ“¡ æ­£åœ¨è·å– {platform} çƒ­æœ...")
        data = fetch_hot_search(platform, args.hot_search_api, args.max_retries, args.retry_delay)

        if data:
            topics = extract_hot_topics(data, platform, args.topics_per_platform)
            if topics:
                all_topics[platform] = topics
                print(f"âœ… {platform}: è·å–åˆ° {len(topics)} æ¡çƒ­æœ")
            else:
                print(f"âš ï¸  {platform}: æœªèƒ½æå–åˆ°çƒ­æœå†…å®¹")

        time.sleep(0.5)

    if not all_topics:
        print("\nâŒ æœªèƒ½è·å–åˆ°ä»»ä½•çƒ­æœæ•°æ®ï¼Œè¯·æ£€æŸ¥APIæœåŠ¡æ˜¯å¦æ­£å¸¸")
        return

    print("\n" + "="*60)
    print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Ollama åˆ†æçƒ­æœè¶‹åŠ¿...")
    print("="*60 + "\n")

    topics_text = ""
    for platform, topics in all_topics.items():
        topics_text += f"\nã€{platform}ã€‘\n"
        for i, topic in enumerate(topics, 1):
            topics_text += f"{i}. {topic}\n"

    prompt = f"""è¯·é˜…è¯»ä»¥ä¸‹æ¥è‡ªå¤šä¸ªå¹³å°çš„çƒ­æœæ•°æ®ï¼Œå†™ä¸€ç¯‡æµç•…çš„æ€»ç»“æŠ¥å‘Šï¼Œæè¿°å½“å‰ç½‘ç»œçƒ­é—¨è¶‹åŠ¿ã€‚

{topics_text}

è¦æ±‚ï¼š
- ç”¨è‡ªç„¶æµç•…çš„æ®µè½å½¢å¼å†™ä½œï¼Œä¸è¦ä½¿ç”¨åˆ†ç‚¹åˆ—è¡¨æˆ–æ ‡é¢˜
- è¦å°†è¶‹åŠ¿åˆ†æå’Œå…·ä½“äº‹å®æœ‰æœºç»“åˆï¼Œå°¤å…¶è¦æ˜ç¡®æŒ‡å‡ºä¿¡æºå“ªä¸ªå¹³å°ã€åŸå§‹å†…å®¹æ˜¯ä»€ä¹ˆ
- è¢«å¤šä¸ªå¹³å°æåˆ°çš„å†…å®¹é‡ç‚¹åˆ†æ
- å…¨æ–‡æ§åˆ¶åœ¨300-500å­—ï¼Œè¯­è¨€ä¸“ä¸šä½†æ˜“è¯»

è¯·ç”¨ä¸­æ–‡æ’°å†™è¿™ç¯‡æ€»ç»“ã€‚"""

    analysis_result = call_ollama(prompt, args.ollama_api, args.ollama_model,
                                  args.max_retries, args.retry_delay)

    if analysis_result:
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æç»“æœ")
        print("="*60)
        print(analysis_result)
        print("\n" + "="*60)

        os.makedirs(args.save_dir, exist_ok=True)
        output = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "platforms_analyzed": list(all_topics.keys()),
            "raw_data": all_topics,
            "analysis": analysis_result
        }
        filename = os.path.join(args.save_dir,
                                f"hot_trends_analysis_{time.strftime('%Y%m%d_%H%M%S')}.json")

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜è‡³: {filename}")
    else:
        print("\nâŒ Ollamaåˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")


if __name__ == "__main__":
    print("="*60)
    print("   ç½‘ç»œçƒ­æœåˆ†æå·¥å…· - å‘½ä»¤è¡Œé…ç½®ç‰ˆ")
    print("="*60 + "\n")

    args = parse_args()
    analyze_hot_trends(args)

    print("\nâœ¨ åˆ†æå®Œæˆï¼")